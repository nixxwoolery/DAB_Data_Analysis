{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43326362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.9\r\n"
     ]
    }
   ],
   "source": [
    "# Check the python version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2258fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#File input/output\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "#JSON file handling\n",
    "import json\n",
    "\n",
    "#Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "\n",
    "#GUI\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from tkinter.filedialog import asksaveasfile\n",
    "from tkinter.filedialog import asksaveasfilename\n",
    "\n",
    "#Date and Time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e856f",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3132aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle missing values\n",
    "missing_values = [\"NaN\", \"\", \" \"]\n",
    "df = None\n",
    "drop_ngr_values = ['NZ02553847', 'SE213515', 'NT05399374', 'NT25265908']\n",
    "dab_multiplexes = ['C18A', 'C18F', 'C188']\n",
    "\n",
    "json_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8780363",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c530d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the CSV file and convert them to JSON\n",
    "def load_csv_files():\n",
    "    global df\n",
    "\n",
    "    file_paths = filedialog.askopenfilenames(title=\"Select CSV Files\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "    if len(file_paths) < 2:\n",
    "        messagebox.showerror(\"Error\", \"Please select at least two CSV files.\")\n",
    "        return\n",
    "\n",
    "    # Read the first CSV file to initialize the DataFrame\n",
    "    try:\n",
    "        df = pd.read_csv(file_paths[0], encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(file_paths[0], encoding='latin')\n",
    "    \n",
    "    for file_path in file_paths[1:]:\n",
    "        try:\n",
    "            combined_df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            combined_df = pd.read_csv(file_path, encoding='latin')\n",
    "\n",
    "        # Merge based on 'id' column\n",
    "        df = df.merge(combined_df, how='outer', on='id')\n",
    "\n",
    "    # Generate a unique filename for backup\n",
    "    backup_filename = f\"data_{time.strftime('%Y%m%d%H%M%S')}.json\"\n",
    "    \n",
    "    # Translate DataFrame to JSON format\n",
    "    json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "    # Save the JSON data to a file (for backup)\n",
    "    with open(backup_filename, \"w\") as file:\n",
    "        file.write(json_data)\n",
    "\n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"CSV files loaded and converted to JSON format successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faa6bb6",
   "metadata": {},
   "source": [
    "# Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6133f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the data\n",
    "def clean_data():\n",
    "    global df\n",
    "\n",
    "    # Drop columns with no data\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    # Handling missing values for float64 columns\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'float64':\n",
    "            df[column].fillna(0, inplace=True)\n",
    "            \n",
    "    # Convert 'In-Use ERP Total' column to float\n",
    "    df['In-Use ERP Total'] = df['In-Use ERP Total'].str.replace(',', '').astype(float)\n",
    "    \n",
    "    # Round the 'In-Use ERP Total' column to 2 decimal places\n",
    "    df['In-Use ERP Total'] = df['In-Use ERP Total'].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7c2566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the data and display the first five rows\n",
    "def clean_and_display_data():\n",
    "    global df\n",
    "\n",
    "    # Check if data is loaded\n",
    "    if df is None:\n",
    "        messagebox.showerror(\"Error\", \"No data available. Please load data first.\")\n",
    "        return\n",
    "\n",
    "    # Clean the data\n",
    "    clean_data()\n",
    "    \n",
    "    # Display the cleaned data in the output text area\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    output_text.insert(tk.END, df.head(5).to_string(index=False))\n",
    "    output_text.insert(tk.END, f\"\\n\\nNumber of Rows: {df.shape[0]}\\nNumber of Columns: {df.shape[1]}\")\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "    \n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"Data cleaned successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c56fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Function to load the CSV file and convert them to JSON\n",
    "def load_csv_files():\n",
    "    global df\n",
    "    \n",
    "    file_paths = filedialog.askopenfilenames(title=\"Select CSV Files\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "    if len(file_paths) < 2:\n",
    "        messagebox.showerror(\"Error\", \"Please select at least two CSV files.\")\n",
    "        return\n",
    "\n",
    "    # Read the first CSV file to initialize the DataFrame\n",
    "    try:\n",
    "        df = pd.read_csv(file_paths[0], encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(file_paths[0], encoding='latin')\n",
    "        \n",
    "    # Create a thread for each file loading\n",
    "    threads = []\n",
    "    for file_path in file_paths[1:]:\n",
    "        thread = threading.Thread(target=load_csv_thread, args=(file_path,))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    # Wait for all threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    # Generate a unique filename for backup\n",
    "    backup_filename = f\"data_{time.strftime('%Y%m%d%H%M%S')}.json\"\n",
    "    \n",
    "    # Translate DataFrame to JSON format\n",
    "    json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "    # Save the JSON data to a file (for backup)\n",
    "    with open(backup_filename, \"w\") as file:\n",
    "        file.write(json_data)\n",
    "\n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"CSV files loaded and converted to JSON format successfully!\")\n",
    "    \n",
    "\n",
    "# Thread function for loading CSV files\n",
    "def load_csv_thread(file_path):\n",
    "    global df\n",
    "\n",
    "    try:\n",
    "        combined_df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        combined_df = pd.read_csv(file_path, encoding='latin')\n",
    "\n",
    "    # Merge based on 'id' column\n",
    "    with thread_lock:\n",
    "        df = df.merge(combined_df, how='outer', on='id')\n",
    "\n",
    "# Function to clean the data\n",
    "def clean_data():\n",
    "    global df\n",
    "\n",
    "    # Drop columns with no data\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    # Handling missing values for float64 columns\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'float64':\n",
    "            df[column].fillna(0, inplace=True)\n",
    "            \n",
    "    # Convert 'In-Use ERP Total' column to float\n",
    "    df['In-Use ERP Total'] = df['In-Use ERP Total'].str.replace(',', '').astype(float)\n",
    "    \n",
    "    # Round the 'In-Use ERP Total' column to 2 decimal places\n",
    "    df['In-Use ERP Total'] = df['In-Use ERP Total'].round(2)\n",
    "\n",
    "# Thread-safe lock\n",
    "thread_lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e498f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop the specified NGR values\n",
    "def drop_ngr_values():\n",
    "    global df\n",
    "\n",
    "    ngr_input = ngr_entry.get().strip()\n",
    "    if ngr_input:\n",
    "        drop_ngr_values = [ngr.strip() for ngr in ngr_input.split(',')]\n",
    "    else:\n",
    "        drop_ngr_values = ['NZ02553847', 'SE213515', 'NT05399374', 'NT25265908']\n",
    "\n",
    "    # Filter and display the rows with the specified NGR values\n",
    "    rows_with_ngr = df[df['NGR'].isin(drop_ngr_values)]\n",
    "\n",
    "    # Clear the output text area and display the new data\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    output_text.insert(tk.END, rows_with_ngr.to_string(index=False))\n",
    "    output_text.insert(tk.END, f\"\\n\\nNumber of Rows: {rows_with_ngr.shape[0]}\\nNumber of Columns: {rows_with_ngr.shape[1]}\")\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "\n",
    "    # Enable the confirm button\n",
    "    confirm_button.config(state=tk.NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b14464fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to confirm and drop the rows with the specified NGR values\n",
    "def confirm_drop_rows():\n",
    "    global df\n",
    "\n",
    "    ngr_input = ngr_entry.get().strip()\n",
    "    if ngr_input:\n",
    "        drop_ngr_values = [ngr.strip() for ngr in ngr_input.split(',')]\n",
    "    else:\n",
    "        drop_ngr_values = ['NZ02553847', 'SE213515', 'NT05399374', 'NT252675908']\n",
    "\n",
    "    # Drop the rows with the specified NGR values\n",
    "    df = df[~df['NGR'].isin(drop_ngr_values)]\n",
    "\n",
    "    # Disable the confirm button\n",
    "    confirm_button.config(state=tk.DISABLED)\n",
    "    \n",
    "     # Disable the confirm button\n",
    "    confirm_button.config(state=tk.DISABLED)\n",
    "\n",
    "    # Clear the output text area and display the cleaned data\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    output_text.insert(tk.END, df.head(10).to_string(index=False))\n",
    "    output_text.insert(tk.END, f\"\\n\\nNumber of Rows: {df.shape[0]}\\nNumber of Columns: {df.shape[1]}\")\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "    \n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"Rows dropped successfully! Data cleaning is complete! You can now move on to Reshaping the Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ef918",
   "metadata": {},
   "source": [
    "# Reshaping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d3cc1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract DAB multiplex information from 'EID' column\n",
    "def get_dab_info(eid_value, multiplex):\n",
    "    if isinstance(eid_value, str) and multiplex in eid_value:\n",
    "        split_values = eid_value.split(',')\n",
    "        index = dab_multiplexes.index(multiplex)\n",
    "        if index < len(split_values):\n",
    "            return split_values[index].strip()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea96a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create new columns for DAB multiplexes\n",
    "def create_dab_columns():\n",
    "    global df, dab_multiplexes\n",
    "\n",
    "    # Get user input for DAB multiplex columns\n",
    "    dab_columns_input = dab_multiplex_entry.get().strip()\n",
    "    if dab_columns_input:\n",
    "        dab_columns = [column.strip() for column in dab_columns_input.split(',')]\n",
    "    else:\n",
    "        dab_columns = dab_multiplexes\n",
    "\n",
    "    # Extract DAB multiplex information from 'EID' column to new columns\n",
    "    for column in dab_columns:\n",
    "        df[column] = df['EID'].apply(lambda x: get_dab_info(x, column))\n",
    "\n",
    "     # Clear the output text area and display the cleaned data\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    output_text.insert(tk.END, df.head(10).to_string(index=False))\n",
    "    output_text.insert(tk.END, f\"\\n\\nNumber of Rows: {df.shape[0]}\\nNumber of Columns: {df.shape[1]}\")\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "    \n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"DAB multiplex columns created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f663fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and display ERP statistics\n",
    "def calculate_erp_statistics():\n",
    "    global df\n",
    "\n",
    "    # Check if data is available and new_df is created\n",
    "    if df is None:\n",
    "        messagebox.showerror(\"Error\", \"No data available. Please load data first.\")\n",
    "        return\n",
    "\n",
    "    # Calculate mean, mode, and median for 'Power(kW)'\n",
    "    mean_erp = df['Power(kW)'].mean()\n",
    "    mode_erp = df['Power(kW)'].mode().iloc[0]\n",
    "    median_erp = df['Power(kW)'].median()\n",
    "\n",
    "    # Display the calculated statistics in the output text area\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    output_text.insert(tk.END, f\"Mean Power(kW): {mean_erp:.2f}\\n\")\n",
    "    output_text.insert(tk.END, f\"Mode Power(kW): {mode_erp:.2f}\\n\")\n",
    "    output_text.insert(tk.END, f\"Median Power(kW): {median_erp:.2f}\\n\")\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "\n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"ERP statistics calculated and displayed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b7f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_join():\n",
    "    global df, dab_multiplexes\n",
    "\n",
    "    # Check if data is loaded\n",
    "    if df is None:\n",
    "        messagebox.showerror(\"Error\", \"No data available. Please load data first.\")\n",
    "        return\n",
    "\n",
    "    # Filter the DataFrame to get rows with specified EID values\n",
    "    selected_rows = df[df['EID'].isin(dab_multiplexes)]\n",
    "\n",
    "    # Create a new DataFrame with desired columns\n",
    "    selected_columns = ['id', 'Date','EID', 'NGR', 'Site', 'Site Height', 'In-Use Ae Ht', 'In-Use ERP Total']\n",
    "    new_df = selected_rows[selected_columns].copy()\n",
    "\n",
    "    # Rename columns\n",
    "    new_df.rename(columns={'In-Use Ae Ht': 'Aerial height(m)', 'In-Use ERP Total': 'Power(kW)'}, inplace=True)\n",
    "\n",
    "    # Reset the index of the new DataFrame\n",
    "    new_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Update the output text area with the content of the new DataFrame\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    output_text.insert(tk.END, new_df.to_string(index=False))\n",
    "    output_text.insert(tk.END, f\"\\n\\nNumber of Rows: {new_df.shape[0]}\\nNumber of Columns: {new_df.shape[1]}\")\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "\n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"New DataFrame created successfully!\")\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c0ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a21ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c55a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7320b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2b01873",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5603a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and display ERP statistics\n",
    "def erp_statistics():\n",
    "    global df\n",
    "\n",
    "    # Check if data is available and new_df is created\n",
    "    if df is None:\n",
    "        messagebox.showerror(\"Error\", \"No data available. Please load data first.\")\n",
    "        return\n",
    "    \n",
    "    # Filter the DataFrame to get rows with specified EID values\n",
    "    selected_rows = df[df['EID'].isin(dab_multiplexes)]\n",
    "\n",
    "    # Create a new DataFrame with desired columns\n",
    "    selected_columns = ['id','EID', 'NGR', 'Site', 'Site Height', 'In-Use Ae Ht', 'In-Use ERP Total']\n",
    "    new_df = selected_rows[selected_columns].copy()\n",
    "    \n",
    "    # Rename columns\n",
    "    new_df.rename(columns={'In-Use Ae Ht': 'Aerial height(m)', 'In-Use ERP Total': 'Power(kW)'}, inplace=True)\n",
    "\n",
    "    # Calculate mean, mode, and median for 'Power(kW)'\n",
    "    mean_erp = new_df['Power(kW)'].mean()\n",
    "    mode_erp = new_df['Power(kW)'].mode().iloc[0]\n",
    "    median_erp = new_df['Power(kW)'].median()\n",
    "\n",
    "    # Display the calculated statistics in the output text area\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    output_text.insert(tk.END, f\"Statistics for Power(kW):\\n\")\n",
    "    output_text.insert(tk.END, f\"Mean Power(kW): {mean_erp:.2f}\\n\")\n",
    "    output_text.insert(tk.END, f\"Mode Power(kW): {mode_erp:.2f}\\n\")\n",
    "    output_text.insert(tk.END, f\"Median Power(kW): {median_erp:.2f}\\n\")\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "\n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"ERP statistics calculated and displayed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c80a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and display Site Height statistics\n",
    "def site_height_statistics():\n",
    "    global df\n",
    "\n",
    "    # Check if data is available and new_df is created\n",
    "    if df is None:\n",
    "        messagebox.showerror(\"Error\", \"No data available. Please load data first.\")\n",
    "        return\n",
    "    \n",
    "    # Filter the DataFrame to get rows with specified EID values\n",
    "    selected_rows = df[df['EID'].isin(dab_multiplexes)]\n",
    "\n",
    "    # Create a new DataFrame with desired columns\n",
    "    selected_columns = ['id','EID', 'NGR', 'Site', 'Site Height', 'In-Use Ae Ht', 'In-Use ERP Total']\n",
    "    new_df = selected_rows[selected_columns].copy()\n",
    "\n",
    "    # Rename columns\n",
    "    new_df.rename(columns={'In-Use Ae Ht': 'Aerial height(m)', 'In-Use ERP Total': 'Power(kW)'}, inplace=True)\n",
    "\n",
    "    # Filter new_df for Site Height > 75\n",
    "    filtered_df = new_df[new_df['Site Height'] > 75]\n",
    "\n",
    "    # Calculate mean, mode, and median for Site Height\n",
    "    mean_site_height = filtered_df['Site Height'].mean()\n",
    "    mode_site_height = filtered_df['Site Height'].mode().iloc[0]\n",
    "    median_site_height = filtered_df['Site Height'].median()\n",
    "\n",
    "    # Display the calculated statistics in the output text area\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    output_text.insert(tk.END, f\"Statistics for Site Height > 75:\\n\")\n",
    "    output_text.insert(tk.END, f\"Mean Site Height: {mean_site_height:.2f}\\n\")\n",
    "    output_text.insert(tk.END, f\"Mode Site Height: {mode_site_height:.2f}\\n\")\n",
    "    output_text.insert(tk.END, f\"Median Site Height: {median_site_height:.2f}\\n\")\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "\n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"Site Height statistics calculated and displayed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0615d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and display Date statistics\n",
    "def date_statistics():\n",
    "    global df\n",
    "\n",
    "    # Check if data is available and new_df is created\n",
    "    if df is None:\n",
    "        messagebox.showerror(\"Error\", \"No data available. Please load data first.\")\n",
    "        return\n",
    "    \n",
    "    # Filter the DataFrame to get rows with specified EID values\n",
    "    selected_rows = df[df['EID'].isin(dab_multiplexes)]\n",
    "\n",
    "    # Create a new DataFrame with desired columns\n",
    "    selected_columns = ['id', 'Date','EID', 'NGR', 'Site', 'Site Height', 'In-Use Ae Ht', 'In-Use ERP Total']\n",
    "    new_df = selected_rows[selected_columns].copy()\n",
    "\n",
    "    # Rename columns\n",
    "    new_df.rename(columns={'In-Use Ae Ht': 'Aerial height(m)', 'In-Use ERP Total': 'Power(kW)'}, inplace=True)\n",
    "    \n",
    "    # Convert 'Date' column to datetime\n",
    "    new_df['Date'] = pd.to_datetime(new_df['Date'], dayfirst=True)\n",
    "    \n",
    "    # Filter new_df for Date from 2001 onwards\n",
    "    filtered_df = new_df[new_df['Date'].dt.year >= 2001]\n",
    "\n",
    "    # Calculate mean, mode, and median for Date\n",
    "    mean_date = filtered_df['Date'].mean()\n",
    "    mode_date = filtered_df['Date'].mode().iloc[0]\n",
    "    median_date = filtered_df['Date'].median()\n",
    "\n",
    "    # Display the calculated statistics in the output text area\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    output_text.insert(tk.END, f\"Statistics for Date from 2001 onwards:\\n\")\n",
    "    output_text.insert(tk.END, f\"Mean Date: {mean_date}\\n\")\n",
    "    output_text.insert(tk.END, f\"Mode Date: {mode_date}\\n\")\n",
    "    output_text.insert(tk.END, f\"Median Date: {median_date}\\n\")\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "\n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"Date statistics calculated and displayed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b916ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "794af5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear the output area\n",
    "def clear_output_area():\n",
    "    \n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    output_text.config(state=tk.DISABLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a218906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and display the DataFrame \n",
    "def view_dab_multiplexes():\n",
    "    \n",
    "    # Filter the DataFrame to get rows with specified EID values\n",
    "    selected_rows = df[df['EID'].isin(dab_multiplexes)]\n",
    "    \n",
    "    # Create a new DataFrame with desired columns\n",
    "    new_columns = ['Site', 'Freq.', 'Block', 'Serv Label1 ', 'Serv Label2 ', 'Serv Label3 ', 'Serv Label4 ', 'Serv Label10 ']\n",
    "    new_df = selected_rows[new_columns].copy()\n",
    "    \n",
    "    # Group data by 'Site' and calculate count for each category\n",
    "    new_df_grouped = new_df.groupby('Site').size().reset_index(name='Count')\n",
    "    \n",
    "    # Update the output text area with the content of the new DataFrame\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    output_text.insert(tk.END, new_df.to_string(index=False))\n",
    "    output_text.insert(tk.END, f\"\\n\\nNumber of Rows: {new_df.shape[0]}\\nNumber of Columns: {new_df.shape[1]}\")\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "    \n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"New DataFrame created and displayed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bcae871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the data to a graph (Heatmap)\n",
    "def plot_dab_multiplexes():\n",
    "    \n",
    "    # Clear the output area\n",
    "    clear_output_area()\n",
    "    \n",
    "    # Filter the DataFrame to get rows with specified EID values\n",
    "    selected_rows = df[df['EID'].isin(dab_multiplexes)]\n",
    "    \n",
    "    # Create a new DataFrame with desired columns\n",
    "    new_columns = ['Site', 'Freq.', 'Block', 'Serv Label1 ', 'Serv Label2 ', 'Serv Label3 ', 'Serv Label4 ', 'Serv Label10 ']\n",
    "    new_df = selected_rows[new_columns].copy()\n",
    "    \n",
    "    # Pivot the DataFrame to have 'Serv Label' as columns and 'Site' as index\n",
    "    pivoted_df = new_df.pivot_table(index='Site', columns='Freq.', aggfunc='size', fill_value=0)\n",
    "\n",
    "    # Create a heatmap using seaborn\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(pivoted_df, cmap='YlGnBu', annot=True, fmt='d')\n",
    "    plt.title(\"DAB Multiplexes Heat Map\")\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Site\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "   # Clear the output text area and display the plot\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    canvas = FigureCanvasTkAgg(plt.gcf(), master=output_text)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=1)\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "    \n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"DAB Multiplexes graph generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7762cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdd8bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the correlation significance\n",
    "def correlation_significance():\n",
    "    # Filter the DataFrame to get rows with specified EID values\n",
    "    selected_rows = df[df['EID'].isin(dab_multiplexes)]\n",
    "    \n",
    "    # Create a new DataFrame with desired columns\n",
    "    new_columns = ['Freq.', 'Block', 'Serv Label1 ', 'Serv Label2 ', 'Serv Label3 ', 'Serv Label4 ', 'Serv Label10 ']\n",
    "    new_df = selected_rows[new_columns].copy()\n",
    "\n",
    "    # Calculate the correlation matrix with p-values\n",
    "    correlation_matrix = new_df.corr(method='pearson', numeric_only=True)\n",
    "    \n",
    "    # Calculate the p-values for correlations\n",
    "    p_values = new_df.corr(method=lambda x, y: np.round(scipy.stats.pearsonr(x, y)[1]), numeric_only=True)\n",
    "    \n",
    "    # Create a mask for significant correlations\n",
    "    significance_level = 0.5\n",
    "    significance_mask = p_values < significance_level\n",
    "    \n",
    "    # Update the correlation matrix with non-significant correlations masked out\n",
    "    correlation_matrix[~significance_mask] = 0\n",
    "    \n",
    "    # Convert the correlation matrix to a formatted string\n",
    "    correlation_text = correlation_matrix.to_string(float_format=\"{:.2f}\".format)\n",
    "    \n",
    "    # Determine if there is any significant correlation\n",
    "    is_significant = significance_mask.any().any()\n",
    "    \n",
    "    # Update the output text area with the correlation information\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    if is_significant:\n",
    "        output_text.insert(tk.END, \"There is significant correlation between the selected columns.\\n\")\n",
    "    else:\n",
    "        output_text.insert(tk.END, \"There is no significant correlation between the selected columns.\\n\")\n",
    "    \n",
    "    # Clear the output area\n",
    "    clear_output_area()\n",
    "    \n",
    "    # Display the correlation information\n",
    "    output_text.insert(tk.END, correlation_text)\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "    \n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"Correlation analysis completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c8c655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of the correlation significance using a heatmap\n",
    "def plot_correlation_heatmap():\n",
    "    \n",
    "    # Clear the output area\n",
    "    clear_output_area()\n",
    "    \n",
    "    # Filter the DataFrame to get rows with specified EID values\n",
    "    selected_rows = df[df['EID'].isin(dab_multiplexes)]\n",
    "    \n",
    "    # Create a new DataFrame with desired columns\n",
    "    new_columns = ['Site', 'Freq.', 'Block', 'Serv Label1 ', 'Serv Label2 ', 'Serv Label3 ', 'Serv Label4 ', 'Serv Label10 ']\n",
    "    new_df = selected_rows[new_columns].copy()\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = new_df.corr()\n",
    "    \n",
    "    # Create a heatmap using seaborn\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", center=0)\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "   \n",
    "    # Display the plot in the GUI\n",
    "    output_text.config(state=tk.NORMAL)\n",
    "    output_text.delete(\"1.0\", tk.END)  # Clear previous content\n",
    "    canvas = FigureCanvasTkAgg(plt.gcf(), master=output_text)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=1)\n",
    "    output_text.config(state=tk.DISABLED)\n",
    "    \n",
    "    # Provide feedback to the user\n",
    "    status_label.config(text=\"Correlation Heatmap generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc31b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23259214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bed542b",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41993d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"DAB Data Analysis\")\n",
    "root.geometry(\"880x650\")\n",
    "\n",
    "# Screen width and height\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "\n",
    "# Centre the window\n",
    "x = (screen_width - root.winfo_reqwidth()) // 2\n",
    "y = (screen_height - root.winfo_reqheight()) // 2\n",
    "root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "# Notebooks(Tabs)\n",
    "notebook = ttk.Notebook(root)\n",
    "notebook.grid(row=0, column=0, columnspan=6)\n",
    "\n",
    "#Window Tabs\n",
    "clean_tab = ttk.Frame(notebook)\n",
    "reshape_tab = ttk.Frame(notebook)\n",
    "stats_tab = ttk.Frame(notebook)\n",
    "visualise_tab = ttk.Frame(notebook)\n",
    "\n",
    "notebook.add(clean_tab, text=\"Data Loading and Cleaning\")\n",
    "notebook.add(reshape_tab, text=\"Reshape the DataFrame\")\n",
    "notebook.add(stats_tab, text =\"Statistical Analysis\")\n",
    "notebook.add(visualise_tab, text=\"Data Visualisation and Correlation Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a75e5026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f72a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Button to load CSV files\n",
    "load_button_label = tk.Label(clean_tab, text=\"Upload Your CSV Files\", relief=tk.FLAT)\n",
    "load_button = tk.Button(clean_tab, text=\"Browse\", command=load_csv_files)\n",
    "\n",
    "# Button to clean and display data\n",
    "clean_button_label= tk.Label(clean_tab, text=\"Clean and Display the Data\")\n",
    "clean_button = tk.Button(clean_tab, text=\"Clean\", command=clean_and_display_data)\n",
    "\n",
    "# Layout\n",
    "load_button_label.grid(row=1, column=0, padx=10, pady=10)\n",
    "load_button.grid(row=1, column=3, padx=10, pady=10)\n",
    "\n",
    "clean_button_label.grid(row=2, column=0, padx=10, pady=10)\n",
    "clean_button.grid(row=2, column=3, padx=10, pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74b072bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NGR Values\n",
    "# Label, input box, submit and confirmation for NGR values to be dropped\n",
    "ngr_label = tk.Label(clean_tab, text=\"Enter NGR Values to be dropped:\")\n",
    "ngr_entry_var = tk.StringVar(value=\"NZ02553847, SE213515, NT05399374, NT25265908\")\n",
    "ngr_entry = tk.Entry(clean_tab, textvariable=ngr_entry_var)\n",
    "submit_button = tk.Button(clean_tab, text=\"Submit\", command=drop_ngr_values)\n",
    "confirm_button = tk.Button(clean_tab, text=\"Confirm\", state=tk.NORMAL, command=confirm_drop_rows)\n",
    "\n",
    "# Layout the widgets for NGR values\n",
    "ngr_label.grid(row=4, column=0, padx=10, pady=10)\n",
    "ngr_entry.grid(row=4, column=1, padx=10, pady=10)\n",
    "submit_button.grid(row=4, column=2, padx=10, pady=10)\n",
    "confirm_button.grid(row=4, column=3, padx=10, pady=10)\n",
    "\n",
    "# Enable the Confirm button\n",
    "confirm_button.config(state=tk.NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c11cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf055224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add DAB multiplex columns\n",
    "# Label, input, and submit button for inputting DAB multiplex columns\n",
    "dab_multiplex_label = tk.Label(reshape_tab, text=\"Enter DAB Multiplex Columns (comma-separated):\")\n",
    "dab_multiplex_entry_var = tk.StringVar(value=\"C18A, C18F, C188\")\n",
    "dab_multiplex_entry = tk.Entry(reshape_tab, textvariable=dab_multiplex_entry_var)\n",
    "dab_multiplex_submit_button = tk.Button(reshape_tab, text=\"Submit\", command=create_dab_columns)\n",
    "\n",
    "# Join DAB multiplex categories to DAB station locations\n",
    "extract_and_join_label = tk.Label(reshape_tab, text=\"Extract DAB Multiplexes and Join to DAB Station Locations\")\n",
    "extract_button = tk.Button(reshape_tab, text=\"Extract and Join Data\", command=extract_and_join)\n",
    "\n",
    "\n",
    "# Layout\n",
    "dab_multiplex_label.grid(row=1, column=0, padx=10, pady=10, sticky=\"e\")\n",
    "dab_multiplex_entry.grid(row=1, column=1, padx=10, pady=10, sticky=\"w\")\n",
    "dab_multiplex_submit_button.grid(row=1, column=2, padx=10, pady=10)\n",
    "\n",
    "extract_and_join_label.grid(row=2, column=0, padx=10, pady=10, sticky=\"e\")\n",
    "extract_button.grid(row=2, column=2, padx=10, pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d3d7ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ea55c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ERP statistics\n",
    "erp_statistics_label = tk.Label(stats_tab, text=\"Calculate ERP Statistics\")\n",
    "erp_statistics_button = tk.Button(stats_tab, text=\"Calculate\", command=erp_statistics)\n",
    "\n",
    "# Calculate Site Height statistics\n",
    "site_height_statistics_label = tk.Label(stats_tab, text=\"Calculate Site Height Statistics\")\n",
    "site_height_statistics_button = tk.Button(stats_tab, text=\"Calculate\", command=site_height_statistics)\n",
    "\n",
    "# Calculate Date statistics\n",
    "date_statistics_label = tk.Label(stats_tab, text=\"Calculate Date Statistics\")\n",
    "date_statistics_button = tk.Button(stats_tab, text=\"Calculate\", command=date_statistics)\n",
    "\n",
    "\n",
    "# Layout\n",
    "erp_statistics_label.grid(row=1, column=1, padx=10, pady=10)\n",
    "erp_statistics_button.grid(row=1, column=4, padx=10, pady=10)\n",
    "\n",
    "site_height_statistics_label.grid(row=2, column=1, padx=10, pady=10)\n",
    "site_height_statistics_button.grid(row=2, column=4, padx=10, pady=10)\n",
    "\n",
    "date_statistics_label.grid(row=3, column=1, padx=10, pady=10)\n",
    "date_statistics_button.grid(row=3, column=4, padx=10, pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2c40e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04026b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "view_data_for_plot_label = tk.Label(visualise_tab, text=\"View Data for Plotting\")\n",
    "plot_label = tk.Label(visualise_tab, text=\"Plot the Graph\")\n",
    "calculate_correlation_label = tk.Label(visualise_tab, text=\"Calculate Correlation Significance\")\n",
    "correlation_label = tk.Label(visualise_tab, text=\"Plot Correlation\")\n",
    "clear_label = tk.Label(visualise_tab, text=\"Clear\")\n",
    "\n",
    "# Buttons\n",
    "view_data_for_plot_button = tk.Button(visualise_tab, text=\"View\", command=view_dab_multiplexes)\n",
    "plot_button = tk.Button(visualise_tab, text=\"Plot\", command=plot_dab_multiplexes)\n",
    "calculate_correlation_button = tk.Button(visualise_tab, text=\"Calculate\", command=correlation_significance)\n",
    "correlation_button = tk.Button(visualise_tab, text=\"Plot\", command=plot_correlation_heatmap)\n",
    "clear_button = tk.Button(visualise_tab, text=\"Clear\", command=clear_output_area)\n",
    "\n",
    "# Layout\n",
    "view_data_for_plot_label.grid(row=2, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "view_data_for_plot_button.grid(row=2, column=1, padx=10, pady=10, sticky=\"e\")\n",
    "\n",
    "plot_label.grid(row=2, column=4, padx=10, pady=10, sticky=\"w\")\n",
    "plot_button.grid(row=2, column=5, padx=10, pady=10, sticky=\"e\")\n",
    "\n",
    "calculate_correlation_label.grid(row=3, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "calculate_correlation_button.grid(row=3, column=1, padx=10, pady=10, sticky=\"e\")\n",
    "\n",
    "correlation_label.grid(row=3, column=4, padx=10, pady=10, sticky=\"w\")\n",
    "correlation_button.grid(row=3, column=5, padx=10, pady=10, sticky=\"e\")\n",
    "\n",
    "clear_label.grid(row=4, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "clear_button.grid(row=4, column=1, padx=10, pady=10, sticky=\"e\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92284857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output text area to display data\n",
    "output_text = tk.Text(root, wrap=\"none\", height=25, state=tk.DISABLED)\n",
    "output_text.grid(row=6, column=0, columnspan=6, padx=10, pady=5, sticky=\"we\")\n",
    "\n",
    "# Status label\n",
    "status_label = tk.Label(root, text=\"\", bd=1, anchor=tk.W)\n",
    "status_label.grid(row=5, column=0, columnspan=6, padx=10, pady=5, sticky=\"we\")\n",
    "\n",
    "# Styling\n",
    "status_label.config(font=(\"Arial\", 14), fg=\"blue\")\n",
    "#output_text.config(font=(\"Helvetica\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e33141ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-20 18:33:43.629 python[51462:2828491] +[CATransaction synchronize] called within transaction\n",
      "2023-08-20 18:33:43.817 python[51462:2828491] +[CATransaction synchronize] called within transaction\n",
      "2023-08-20 18:34:24.924 python[51462:2828491] Warning: Expected min height of view: (<NSButton: 0x7fe0376690d0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2023-08-20 18:34:30.242 python[51462:2828491] +[CATransaction synchronize] called within transaction\n",
      "2023-08-20 18:34:30.370 python[51462:2828491] +[CATransaction synchronize] called within transaction\n",
      "2023-08-20 18:35:26.215 python[51462:2828491] +[CATransaction synchronize] called within transaction\n",
      "2023-08-20 18:51:41.425 python[51462:2828491] +[CATransaction synchronize] called within transaction\n"
     ]
    }
   ],
   "source": [
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24069517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45f588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282e58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00240211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
